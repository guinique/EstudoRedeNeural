{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "53ba6ebf11ae09001cae39a12ad447a7fc5a8249bdf3facb4372c82840a3f1ad"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BoIBjYKdCHD"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from keras.datasets import mnist #Lecun, 1998\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Conv2D\n",
        "# from keras.layers.convolutional import MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Dropout, Input, MaxPooling2D\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "import glob\n",
        "\n",
        "import random\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "teste = glob.glob(\"C:/Users/Nique/Desktop/COVID-19 Radiography Database/Teste/*\")\n",
        "treino = glob.glob(\"C:/Users/Nique/Desktop/COVID-19 Radiography Database/Treino/*\")\n",
        "\n",
        "# leitura das imagens e dos valores de teste\n",
        "dim = (224, 224)\n",
        "imgTeste = []\n",
        "valTeste = []\n",
        "count = 0\n",
        "for x in teste:\n",
        "    imgAux = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    imgTesteResized= cv2.resize(imgAux,dim, interpolation = cv2.INTER_AREA)\n",
        "    imgTeste.append(imgTesteResized)\n",
        "    if \"NORMAL\" in x:\n",
        "        valTeste.append(0)\n",
        "    else:\n",
        "        valTeste.append(1)\n",
        "    count = count+1\n",
        "\n",
        "# leitura das imagens e dos valores de treino\n",
        "imgTreino = []\n",
        "valTreino = []\n",
        "\n",
        "\n",
        "# construção da rede\n",
        "model = Sequential()\n",
        "model.add(Conv2D(30,(5,5), input_shape=(224,224,1), strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid', name='predict'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# 100 epochs 10 batch = 178 \n",
        "# 100 epochs 50 batch = 36\n",
        "# 100 epochs 100 batch = 18\n",
        "# 300 epochs 10 batch = 77\n",
        "model.fit(imgTreino,valTreino,epochs=5, batch_size=16, validation_data=(imgTeste,valTeste))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(481, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 220, 220, 30)      780       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 110, 110, 30)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 110, 110, 30)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 363000)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               46464128  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "predict (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 46,475,277\n",
            "Trainable params: 46,475,277\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "31/31 [==============================] - 12s 381ms/step - loss: 1.5117 - accuracy: 0.6509 - val_loss: 0.0962 - val_accuracy: 0.9667\n",
            "Epoch 2/5\n",
            "31/31 [==============================] - 12s 378ms/step - loss: 0.0952 - accuracy: 0.9707 - val_loss: 0.0495 - val_accuracy: 0.9854\n",
            "Epoch 3/5\n",
            "31/31 [==============================] - 12s 380ms/step - loss: 0.1048 - accuracy: 0.9651 - val_loss: 0.0197 - val_accuracy: 0.9958\n",
            "Epoch 4/5\n",
            "31/31 [==============================] - 12s 376ms/step - loss: 0.0185 - accuracy: 0.9954 - val_loss: 0.0183 - val_accuracy: 0.9938\n",
            "Epoch 5/5\n",
            "31/31 [==============================] - 12s 396ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.1985 - val_accuracy: 0.9127\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x217a762fac0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scalet' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-2182c27d0490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mscaled_test_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscalet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgValid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'scalet' is not defined"
          ]
        }
      ],
      "source": [
        "validacao = glob.glob(\"C:/Users/Nique/Desktop/COVID-19 Radiography Database/Validacao/*\")\n",
        "imgValid = []\n",
        "valValid = []\n",
        "count = 0\n",
        "for x in validacao:\n",
        "    imgAux = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    imgValidResized= cv2.resize(imgAux,dim, interpolation = cv2.INTER_AREA)\n",
        "    imgValid.append(imgValidResized)\n",
        "    if \"NORMAL\" in x:\n",
        "        valValid.append(0)\n",
        "    else:\n",
        "        valValid.append(1)\n",
        "    count = count+1   \n",
        "\n",
        "scaled_test_samples = scaler.fit_transform(imgValid.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}